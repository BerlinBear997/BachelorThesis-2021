\chapter{Related Work}

\section{Previous researches on the Roofline model}
Ofenbeck et al.  \cite{28} studied how to apply the Roofline model on Intel platforms. They provided an approach to measure the necessary data of a running program and to produce the Roofline plot based on the data. Ilic et al. \cite{27} proposed the cache-aware Roofline model which is able to model the performance on multiple levels of caches. Hill et al. \cite{29} proposed the Gables model which refines the Roofline model in a way that it can be applied on system-on-chips (SoC). SoC is a widely used architecture on modern smartphones. It integrates the CPU, memory, GPU and other necessary components in a single microchip \cite{30}. Gables is able to model the performance bound of different components of SoC which guides the developer to optimise the performance. Kim et al. \cite{31} used the Roofline model to analyse and optimise the performance of the Finite-Difference Time-Domain (FDTD) on GPU. FDTD is a numerical technique to simulate the electromagnetic field \cite{32}. They pointed out that memory access optimisations are most important for GPU.  Ding et al. \cite{33} proposed the instruction Roofline model for GPUs. They used the instruction-oriented approach to characterise the performance which is an inspiration of the implementation in this work. Cabezas et al. \cite{35} extended the Roofline model with multiple hardware-related bottlenecks such as throughput, latency, OoOE buffers and capacity information for a multi-level cache hierarchy. They integrated those bottlenecks into one Roofline plot. Sato et al. \cite{36} model the performance of the vector processors with the vector cache using the Roofline model. They proposed optimisation strategies that reduce energy consumption up to 70\%.


The studies mentioned above apply the Roofline model to model and optimise the performance. This paper aims to dynamically modify the clock frequency to achieve power saving based on the Roofline model. This work differs from them by combining the Roofline model with time interval analysis which characterises the performance bound under memory access latency. 

\section{Previous researches on power management}
Gholkar et al. \cite{21} proposed the uncore power Scavenger (UPScavanger), a runtime system that dynamically changes the uncore frequency to achieve power and energy saving. It is able to detect the execution patterns (memory-bound or compute-bound) of an application based on the changing of the DRAM power and IPC. They compared the UPScavenger with Intel's default uncore power setting and showed that the UPScavenger achieves considerable power saving. They also compared it with Intel's RALP under the same power cap and showed that it speeds up the completion of a task. This paper differs from it by identifying the execution patterns based on the Roofline model and time interval analysis. Besides, work modifies both core and uncore frequency to achieve power saving.
Sundriyal et al. \cite{34} explored how the uncore frequency affects memory latency and bandwidth. They also compared the energy saving of the UFS and DVFS on quantum chemistry application GAMESS. They stated that combining the UFS and DVFS achieves significant energy saving on GAMESS. In this paper, the effect of both core and uncore frequency on memory latency is explored.
Gupta et al. \cite{37} observed the uncore power consumption in a heterogeneous computing system that contains both high and low power cores, which is a typical processor architecture for modern smartphones. They claimed that heterogeneous core architectures have huge advantages over homogeneous for the client device in terms of energy efficiency. They concluded that the uncore component is potentially a huge contribution to power saving.


